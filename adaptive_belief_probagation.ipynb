{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import galois\n",
    "import numpy as np\n",
    "from numpy import binary_repr\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 7\n",
    "number_of_information_bits = 4\n",
    "parity_check_symbols = length - number_of_information_bits\n",
    "field = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "reed_solomon_code = galois.ReedSolomon(7, 4)\n",
    "galois_field = galois.GF(2**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 7 6 3 4 2 1]\n",
      " [7 3 2 5 6 4 1]\n",
      " [6 2 7 4 5 3 1]]\n"
     ]
    }
   ],
   "source": [
    "parity_check_matrix = reed_solomon_code.H\n",
    "print(parity_check_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4 3 6 7 5]\n",
      " [1 4 6 5 2 3 7]\n",
      " [1 3 5 4 7 2 6]]\n"
     ]
    }
   ],
   "source": [
    "parity_check_matrix_np = np.flip(np.array(parity_check_matrix), 1)\n",
    "print(parity_check_matrix_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 5 0]\n"
     ]
    }
   ],
   "source": [
    "random_message = galois_field.Random(reed_solomon_code.k)\n",
    "print(random_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 5 0 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "encoded_message = reed_solomon_code.encode(random_message)\n",
    "print(encoded_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 5 0 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "encoded_message_np = np.array(encoded_message)\n",
    "print(encoded_message_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the amount of noise to add to the channel. Will also be used to calculate the error at the end of the channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# change the symbols to binary\n",
    "def symbols_to_binary(symbols, width=3):\n",
    "\t\tbinary = np.zeros((len(symbols), width), dtype=int)\n",
    "\t\tfor i in range(len(symbols)):\n",
    "\t\t\t\tbinary[i] = np.array([int(x) for x in binary_repr(symbols[i], width=3)])\n",
    "\t\treturn binary.flatten()\n",
    "\n",
    "encoded_message_binary = symbols_to_binary(encoded_message_np, width=field)\n",
    "print(encoded_message_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1 -1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# change to binary phase shift keying (BPSK) symbols\n",
    "encoded_message_bpsk = 2 * encoded_message_binary - 1\n",
    "print(encoded_message_bpsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "snr_range_db = np.arange(1.0, 10)\n",
    "print(snr_range_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# set the Bit Error Rate (BER) vector \n",
    "bit_error_rate = np.zeros(len(snr_range_db))\n",
    "print(bit_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95811019-0.37777995j  1.57330836+0.28941233j  0.39485198+0.33433859j\n",
      "  0.34749402+0.10303746j  0.26136009+0.28685293j  0.13180739-0.04681581j\n",
      "  1.0212025 -0.31813141j -2.0008147 +1.0003498j   0.82575161+0.38625336j\n",
      " -0.83429991-0.77063941j -0.65785615-0.72977677j -1.79068278-0.88623732j\n",
      " -1.94910327+0.4045919j   1.32917733-0.61963799j  0.79310289-0.21729808j\n",
      " -0.2982404 +1.28283937j  1.89301561-0.52517926j  1.33963105+0.02444858j\n",
      " -1.320379  +0.4506849j  -0.0573461 -0.32490587j  1.33802611+0.55810413j]\n"
     ]
    }
   ],
   "source": [
    "# add noise to the code word \n",
    "def add_noise(encoded_message, snr):\n",
    "    N = len(encoded_message)\n",
    "\n",
    "    # Calculate the standard deviation of the noise from the SNR\n",
    "    sigma = np.sqrt(1 / (2 * 10**(snr / 10)))\n",
    "\n",
    "    # Generate complex Gaussian noise\n",
    "    noise = sigma * (np.random.randn(N) + 1j * np.random.randn(N))\n",
    "\n",
    "    # Add the noise to the signal\n",
    "    received_signal = encoded_message + noise\n",
    "\n",
    "    # received_signal now contains the original signal with added noise corresponding to the current SNR value\n",
    "    return received_signal\n",
    "\n",
    "received_signals = [add_noise(encoded_message_bpsk, snr) for snr in snr_range_db]\n",
    "received_signals_np = np.array(received_signals)\n",
    "print(received_signals_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.41237853 -3.96135575 -0.99417838 -0.87493811 -0.65806573 -0.33187136\n",
      " -2.57123556  5.03775295 -2.07911938  2.10064271  1.65638365  4.50867212\n",
      "  4.90755127 -3.34667023 -1.99691476  0.75092482 -4.76633091 -3.37299114\n",
      "  3.32451735  0.14438893 -3.36895015]\n"
     ]
    }
   ],
   "source": [
    "# calculate the log-likelihood ratio (LLR)\n",
    "def calculate_llr(received_signal, snr):\n",
    "    p_y_given_0 = np.exp(-np.abs(received_signal-(-1))**2/(2*1/(10**(snr/10))))\n",
    "    p_y_given_1 = np.exp(-np.abs(received_signal-1)**2/(2*1/(10**(snr/10))))\n",
    "\n",
    "    return np.log(p_y_given_0/p_y_given_1).real\n",
    "\n",
    "llrs = []\n",
    "for i in range(len(received_signals)):\n",
    "    llrs.append(calculate_llr(received_signals_np[i], snr_range_db[i]))\n",
    "llrs_np = np.array(llrs)\n",
    "print(llrs_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.41237853 3.96135575 0.99417838 0.87493811 0.65806573 0.33187136\n",
      " 2.57123556 5.03775295 2.07911938 2.10064271 1.65638365 4.50867212\n",
      " 4.90755127 3.34667023 1.99691476 0.75092482 4.76633091 3.37299114\n",
      " 3.32451735 0.14438893 3.36895015]\n",
      "(9, 21)\n"
     ]
    }
   ],
   "source": [
    "abs_llrs = np.abs(llrs_np)\n",
    "print(abs_llrs[0])\n",
    "print(abs_llrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0]\n",
      " [0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1]\n",
      " [1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0]\n",
      " [0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0]\n",
      " [0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 0]\n",
      " [1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1]\n",
      " [0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1]\n",
      " [0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0]\n",
      " [1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the binary representation of a number\n",
    "def binary_representation(num, field):\n",
    "    return [int(x) for x in format(num, '0' + str(field) + 'b')]\n",
    "\n",
    "# perform binary image expansion (BIE) on H matrix\n",
    "def binary_image_expansion(H_matrix, field):\n",
    "    nn = len(H_matrix)\n",
    "    z = np.zeros((field, nn), dtype=int)\n",
    "\n",
    "    for j in range(nn):\n",
    "        z[:, j] = binary_representation(H_matrix[j], field)\n",
    "\n",
    "    return z\n",
    "\n",
    "# perform binary image expansion (BIE) on H matrix\n",
    "def perform_binary_image_expansion(parity_check_matrix, field):\n",
    "    shape = parity_check_matrix.shape\n",
    "    n = shape[1]\n",
    "    # Generating GF(2^b) primitive element and bit representation\n",
    "    a = galois.GF(2**field).primitive_element\n",
    "    aa = a**np.arange(n)\n",
    "    cx = np.concatenate((aa, aa[:field-1]))\n",
    "    v = binary_image_expansion(cx, field)\n",
    "\n",
    "    # Generating 3 by 3 square matrices for each element of the field\n",
    "    sq = np.zeros((n, field, field), dtype=int)\n",
    "    for i in range(n):\n",
    "        sq[i,:,:] = v[:,i:i+field]\n",
    "\n",
    "    # Generating Hb matrix\n",
    "    parity_check_symbols = shape[0]  # assuming the number of parity check symbols is the number of rows in H_matrix\n",
    "    Hb = np.zeros((parity_check_symbols*field, n*field), dtype=int)\n",
    "    for i in range(parity_check_symbols):\n",
    "        for j in range(n):\n",
    "            for f in range(n):\n",
    "                 if parity_check_matrix[i,j] == a**(f):\n",
    "                     Hb[i*field:(i+1)*field,j*field:(j+1)*field]=sq[f,:,:]\n",
    "\n",
    "    return Hb\n",
    "\n",
    "parity_check_matrix_binary = perform_binary_image_expansion(parity_check_matrix_np, field)\n",
    "print(parity_check_matrix_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0]\n",
      " [0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1]\n",
      " [0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def sort_indices(prob_matrix, h_matrix):\n",
    "\t\t# Get the indices that would sort the probability matrix\n",
    "\t\tsorted_indices = np.argsort(prob_matrix)\n",
    "\t\t# Sort the probability matrix and H matrix based on the sorted indices\n",
    "\t\tsorted_h_matrix = h_matrix[:, sorted_indices]  # Sort columns of H matrix based on sorted indices\n",
    "\n",
    "\t\t# Perform row reduction on the sorted H matrix\n",
    "\t\tConv_gf = galois_field(sorted_h_matrix)  # Assuming GF is a valid function defined elsewhere\n",
    "\t\tRREF = Conv_gf.row_reduce(eye=\"left\")  # Assuming row_reduce() is a valid method\n",
    "\n",
    "\t\t# Create a new H matrix with the original column indices after RREF\n",
    "\t\toriginal_indices = np.argsort(sorted_indices)  # Getting the original indices\n",
    "\t\tnew_h_matrix = RREF[:, original_indices]  # Reorder columns of RREF based on original indices\n",
    "\t\treturn new_h_matrix\n",
    "#NewH=sort_indices(pm,BB)\n",
    "\n",
    "sorted_indices = [sort_indices(abs_llr, parity_check_matrix_binary) for abs_llr in abs_llrs]\n",
    "field_parity_check_matrix_np = np.array(sorted_indices)\n",
    "print(field_parity_check_matrix_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.33459196  -3.77156947  -0.92728048  -0.97915105  -0.58843807\n",
      "   -0.39236984  -2.45837345   4.92101289  -1.88850729   2.01458091\n",
      "    1.59203484   4.45464643   4.75238342  -3.29760759  -1.93682308\n",
      "    0.69723126  -4.72596766  -3.28912831   3.20525449   0.08254712\n",
      "   -3.26236135]\n",
      " [ -3.84976566  -1.03492828  -4.36458439  -3.52952171  -5.8364068\n",
      "    2.8827131   -3.40562656   2.33494168  -0.7420937    1.60546117\n",
      "    0.66708885   4.28425492   3.38243352  -5.24934156  -4.62020219\n",
      "    0.50849377  -3.05961643  -5.84570686   4.87335958  -4.90727026\n",
      "   -4.73947071]\n",
      " [ -7.47246033  -3.53414729  -5.10657334  -7.49478505  -6.26266323\n",
      "    2.95950001  -1.04272767   7.75395748  -5.59728026   3.38009246\n",
      "    5.84154371   0.35255438   2.66674115  -3.70112805  -3.42739561\n",
      "   -0.48808668  -2.114961    -7.06850338   4.19485783  -2.31621303\n",
      "   -2.02667822]\n",
      " [ -5.90326774  -3.21111272  -7.00843405  -4.83553053  -6.57225491\n",
      "    4.65636635  -7.32426078   9.99003014  -5.34697139   4.14809098\n",
      "    3.72629066   5.30751166   4.49562615  -1.23774879  -2.58893598\n",
      "   -3.56932877  -2.922459    -2.47420294   3.89913775  -3.67469279\n",
      "   -5.79757872]\n",
      " [ -5.3943646   -6.09305057  -4.75150178  -6.52220265  -5.44579971\n",
      "    2.95970858 -11.71728651   4.83698081 -10.76872844   0.55817942\n",
      "    6.00480952   9.54415849   4.43744915  -4.78667089  -8.52733305\n",
      "   -4.20378448  -6.55197089  -9.02024755   8.3932466   -6.43009123\n",
      "   -1.88139846]\n",
      " [ -7.5846959   -6.95704359  -7.77766012  -8.14493014  -4.30288565\n",
      "    8.53605516  -4.3296755    7.3336342   -3.10801781   7.90034889\n",
      "    6.65160499   7.40840944   9.18142055  -9.28198308  -6.84378217\n",
      "   -5.17571149  -4.64786073 -12.57463263   5.3228112   -7.61986466\n",
      "   -8.29038254]\n",
      " [-13.30385455  -7.06425695  -9.85997859 -11.40244594  -9.97266742\n",
      "   11.83563829 -10.60578081   7.18396342  -6.14122581  15.48854251\n",
      "    4.57866617  10.23152768   9.05593344 -15.57547468 -12.05137392\n",
      "  -15.35230525  -6.94735398  -7.41002198   8.85221979  -7.77959046\n",
      "  -10.9185108 ]\n",
      " [-12.33026617 -12.40408186 -15.61241273  -9.86879703  -9.14383406\n",
      "   12.33483845 -15.05163127  13.97790997  -8.23390395  10.85299231\n",
      "   15.04340915   7.05997372  10.8338032  -13.65612693 -11.8867175\n",
      "  -11.59293153 -18.48526481 -16.88106213  17.55143356 -13.74787159\n",
      "  -12.77789523]\n",
      " [ -8.8995496  -20.79077072 -23.06271475 -12.335057   -13.22268714\n",
      "   14.33088796 -17.62725547   8.61032813 -17.29700181  21.14279393\n",
      "   11.3389461   18.79206622  13.46014683 -11.73717149 -11.27364875\n",
      "  -20.42250505 -15.9969653  -13.5307693   12.87497295 -11.80206252\n",
      "  -17.02538236]]\n"
     ]
    }
   ],
   "source": [
    "#Sum product Algorithm\n",
    "def logSPA(binary_parity_check_matrix, llr, number_of_iterations, damping_factor):\n",
    "    \"\"\"\n",
    "    This function performs the SPA decoding algorithm in the log domain.\n",
    "    It is a simplification of the SPA in the log domain.\n",
    "\n",
    "    Arguments:\n",
    "    binary_parity_check_matrix -- The Binary Parity check matrix\n",
    "    LLR -- The log likelihood ratios\n",
    "    number_of_iterations -- Number of iterations\n",
    "    damping_factor -- Damping factor. Not used in decoding of LDPC.\n",
    "\n",
    "    Returns:\n",
    "    V -- The output message at the end of the decoding process\n",
    "    Lj -- The outputted LLRs\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    shape = binary_parity_check_matrix.shape\n",
    "    t = shape[0]\n",
    "    n = shape[1]\n",
    "\n",
    "    Lrij = np.zeros((t, n))\n",
    "    Lqji = binary_parity_check_matrix * np.tile(llr, (t, 1))\n",
    "\n",
    "    Lj = np.zeros(n)\n",
    "    Lext = np.zeros(n)\n",
    "\n",
    "    for _ in range(number_of_iterations):\n",
    "        # The horizontal step\n",
    "        for i in range(t):\n",
    "            cj = np.nonzero(binary_parity_check_matrix[i, :])[0]  # indices of nonzeros in each column\n",
    "            for ij in range(len(cj)):\n",
    "                lij = 1\n",
    "                for in_ in range(len(cj)):\n",
    "                    if in_ != ij:  # all bits except bit n\n",
    "                        lij = lij * np.tanh(Lqji[i, cj[in_]] / 2)\n",
    "                Lrij[i, cj[ij]] = 2 * np.arctanh(lij)  # horizontal step(CN) update\n",
    "\n",
    "        # The vertical step\n",
    "        for j in range(n):\n",
    "            ri = np.nonzero(binary_parity_check_matrix[:,j])[0] # indices of nonzeros in each row\n",
    "\n",
    "            # Finding extrinsic info\n",
    "            Lext[j] = np.sum(Lrij[ri, j])\n",
    "\n",
    "            # Finding Lj (total LLR)\n",
    "            Lj[j] = llr[j] + damping_factor * np.sum(Lrij[ri, j])\n",
    "\n",
    "    return Lj\n",
    "\n",
    "NUMBER_OF_ITERATIONS = 1000\n",
    "DAMPING_FACTOR = 0.05\n",
    "\n",
    "spa_decoders = []\n",
    "for i in range(len(llrs_np)):\n",
    "    spa_decoders.append(logSPA(field_parity_check_matrix_np[i], llrs_np[i], NUMBER_OF_ITERATIONS, DAMPING_FACTOR))\n",
    "spa_decoders_np = np.array(spa_decoders)\n",
    "print(spa_decoders_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "decoded_messages = [(spa_decoder >= 0).astype(int) for spa_decoder in spa_decoders_np]\n",
    "decoded_messages_np = np.array(decoded_messages)\n",
    "print(decoded_messages_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 20, 21, 21, 21, 21, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "num_errors = [np.sum(decoded_message_np != encoded_message_binary) for decoded_message_np in decoded_messages_np]\n",
    "print(num_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
